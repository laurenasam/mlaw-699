{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Case Number                                       Link to H-2A  \\\n",
      "0  H-300-21280-631097  https://seasonaljobs.dol.gov/api/job-order/H-3...   \n",
      "1  H-300-21202-474481  https://seasonaljobs.dol.gov/api/job-order/H-3...   \n",
      "2  H-300-21195-461870  https://seasonaljobs.dol.gov/api/job-order/H-3...   \n",
      "3  H-300-21183-441615  https://seasonaljobs.dol.gov/api/job-order/H-3...   \n",
      "4  H-300-20255-817429  https://seasonaljobs.dol.gov/api/job-order/H-3...   \n",
      "\n",
      "  Hit or No Hit Market Farm Narratives  \\\n",
      "0        No Hit    NaN  NaN        NaN   \n",
      "1        No Hit    NaN  NaN        NaN   \n",
      "2        No Hit    NaN  NaN        NaN   \n",
      "3        No Hit    NaN  NaN        NaN   \n",
      "4        No Hit    NaN  NaN        NaN   \n",
      "\n",
      "  Facebook. Google Reviews, Website, LinkedIn, Google Maps, Instagram, etc.???  \\\n",
      "0                                                NaN                             \n",
      "1                                                NaN                             \n",
      "2                                                NaN                             \n",
      "3                                                NaN                             \n",
      "4                                                NaN                             \n",
      "\n",
      "   Certainty    year      Recruiter Hits - By name or by logo Person  \n",
      "0        NaN  2022.0  D Mendoza - 1                       NaN    NaN  \n",
      "1        NaN  2021.0  D Mendoza - 1                       NaN    NaN  \n",
      "2        NaN  2021.0  D Mendoza - 1                       NaN    NaN  \n",
      "3        NaN  2021.0  D Mendoza - 1                       NaN    NaN  \n",
      "4        NaN  2021.0  D Mendoza - 1                       NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data from csv\n",
    "data = pd.read_csv('Master Document of H-2A Orders - Hit or Not - Previous Semester H-2A Orders Successes.csv')\n",
    "\n",
    "# print the first 5 rows of the data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Case Number                                       Link to H-2A  \\\n",
      "13  H-300-21029-042637  https://seasonaljobs.dol.gov/api/job-order/H-3...   \n",
      "35  H-300-20013-248635  https://seasonaljobs.dol.gov/api/job-order/H-3...   \n",
      "38  H-300-20002-228933  https://seasonaljobs.dol.gov/api/job-order/H-3...   \n",
      "44  H-300-19044-646927  https://seasonaljobs.dol.gov/jobs/H-300-19044-...   \n",
      "48  H-300-19114-230380  https://seasonaljobs.dol.gov/jobs/H-300-19114-...   \n",
      "\n",
      "   Hit or No Hit                                             Market  \\\n",
      "13           Hit                        Kroger, Walmart, Instacart    \n",
      "35           Hit  Naturipe Farms, 99 Cents Only Stores, Ahold, A...   \n",
      "38           Hit  Store Locator ‚Äì sealtheseasons, Peoples-Food A...   \n",
      "44           Hit                             https://wishfarms.com/   \n",
      "48           Hit                                      Harris Teeter   \n",
      "\n",
      "                             Farm  \\\n",
      "13                  Haigler Farms   \n",
      "35         Down South Berries LLC   \n",
      "38                       L&S Farm   \n",
      "44  Major League Blueberries, LLC   \n",
      "48       Sleepy Creek Farms, Inc.   \n",
      "\n",
      "                                           Narratives  \\\n",
      "13  I googled the worksite address on the work ord...   \n",
      "35  H2A list > work order lists Down South Berries...   \n",
      "38  Googled: L&S Farm at 213 Pine Cone Road, Alma,...   \n",
      "44  H2A list > Job order on DOL site, listed busin...   \n",
      "48  H2A > job order work site address > googled an...   \n",
      "\n",
      "   Facebook. Google Reviews, Website, LinkedIn, Google Maps, Instagram, etc.???  \\\n",
      "13                                            Website                             \n",
      "35  website, but also relied on info gained over a...                             \n",
      "38                            Websites, including SoS                             \n",
      "44                                            Website                             \n",
      "48                                     Google reviews                             \n",
      "\n",
      "    Certainty    year      Recruiter Hits - By name or by logo Person  \n",
      "13        3.0  2021.0  D Mendoza - 1                      Both    Ben  \n",
      "35        1.0  2020.0  D Mendoza - 1                      Both    Ben  \n",
      "38        1.0  2020.0  D Mendoza - 1                      Both    Ben  \n",
      "44        3.0  2019.0  D Mendoza - 1                      Logo    Ben  \n",
      "48        2.0  2019.0  D Mendoza - 1                      Name    Ben  \n"
     ]
    }
   ],
   "source": [
    "# make a df of just rows with \"hit\"\n",
    "hit = data[data['Hit or No Hit'] == 'Hit']\n",
    "\n",
    "# print the first 5 rows of the hit data\n",
    "print(hit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the hit data to a new csv\n",
    "hit.to_csv('hit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded: H2A_PDFs/H-300-20013-248635.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-21029-042637.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-20002-228933.pdf\n",
      "‚ö†Ô∏è Not a PDF: https://seasonaljobs.dol.gov/jobs/H-300-19114-230380 (Content-Type: text/html; charset=utf-8)\n",
      "‚ö†Ô∏è Not a PDF: https://seasonaljobs.dol.gov/jobs/H-300-19044-646927 (Content-Type: text/html; charset=utf-8)\n",
      "‚ö†Ô∏è Not a PDF: https://seasonaljobs.dol.gov/jobs/H-300-19068-891355 (Content-Type: text/html; charset=utf-8)\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-20357-975271.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-21006-998351.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-22014-831909.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-20009-241352.pdf\n",
      "‚ö†Ô∏è Not a PDF: https://seasonaljobs.dol.gov/jobs/H-300-19106-808682 (Content-Type: text/html; charset=utf-8)\n",
      "‚ö†Ô∏è Not a PDF: https://seasonaljobs.dol.gov/jobs/H-300-19051-356435 (Content-Type: text/html; charset=utf-8)\n",
      "‚ö†Ô∏è Not a PDF: https://seasonaljobs.dol.gov/jobs/H-300-18254-022527 (Content-Type: text/html; charset=utf-8)\n",
      "‚úÖ Downloaded: H2A_PDFs/104779_order.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/99257_order.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/115969_order.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-23086-881434.pdf\n",
      "‚ö†Ô∏è No 'View Job Order' PDF found on webpage: https://api.seasonaljobs.dol.gov/job-order/H-300-23028-734237\n",
      "‚úÖ Downloaded: H2A_PDFs/115829_order.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/74479_order.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/117179_order.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/66774_order.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-20260-827359.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-20363-980683.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-21007-999949.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-21026-033893.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-21039-063180.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-21124-285763.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-21253-577257.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-21166-398136.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-20208-735658.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-20150-611826.pdf\n",
      "‚úÖ Downloaded: H2A_PDFs/H-300-20051-337029.pdf\n",
      "\n",
      "üìä **Download Summary**\n",
      "‚úÖ Successfully downloaded PDFs: 26\n",
      "‚ùå Failed URLs: 7\n",
      "\n",
      "‚úÖ **Successfully downloaded PDFs:**\n",
      "H2A_PDFs/H-300-20013-248635.pdf\n",
      "H2A_PDFs/H-300-21029-042637.pdf\n",
      "H2A_PDFs/H-300-20002-228933.pdf\n",
      "H2A_PDFs/H-300-20357-975271.pdf\n",
      "H2A_PDFs/H-300-21006-998351.pdf\n",
      "H2A_PDFs/H-300-22014-831909.pdf\n",
      "H2A_PDFs/H-300-20009-241352.pdf\n",
      "H2A_PDFs/104779_order.pdf\n",
      "H2A_PDFs/99257_order.pdf\n",
      "H2A_PDFs/115969_order.pdf\n",
      "H2A_PDFs/H-300-23086-881434.pdf\n",
      "H2A_PDFs/115829_order.pdf\n",
      "H2A_PDFs/74479_order.pdf\n",
      "H2A_PDFs/117179_order.pdf\n",
      "H2A_PDFs/66774_order.pdf\n",
      "H2A_PDFs/H-300-20260-827359.pdf\n",
      "H2A_PDFs/H-300-20363-980683.pdf\n",
      "H2A_PDFs/H-300-21007-999949.pdf\n",
      "H2A_PDFs/H-300-21026-033893.pdf\n",
      "H2A_PDFs/H-300-21039-063180.pdf\n",
      "H2A_PDFs/H-300-21124-285763.pdf\n",
      "H2A_PDFs/H-300-21253-577257.pdf\n",
      "H2A_PDFs/H-300-21166-398136.pdf\n",
      "H2A_PDFs/H-300-20208-735658.pdf\n",
      "H2A_PDFs/H-300-20150-611826.pdf\n",
      "H2A_PDFs/H-300-20051-337029.pdf\n",
      "\n",
      "‚ö†Ô∏è **Failed to download PDFs from these URLs:**\n",
      "https://seasonaljobs.dol.gov/jobs/H-300-19114-230380\n",
      "https://seasonaljobs.dol.gov/jobs/H-300-19044-646927\n",
      "https://seasonaljobs.dol.gov/jobs/H-300-19068-891355\n",
      "https://seasonaljobs.dol.gov/jobs/H-300-19106-808682\n",
      "https://seasonaljobs.dol.gov/jobs/H-300-19051-356435\n",
      "https://seasonaljobs.dol.gov/jobs/H-300-18254-022527\n",
      "https://api.seasonaljobs.dol.gov/job-order/H-300-23028-734237\n",
      "\n",
      "üîç Debugging successful_downloads list:\n",
      "['H2A_PDFs/H-300-20013-248635.pdf', 'H2A_PDFs/H-300-21029-042637.pdf', 'H2A_PDFs/H-300-20002-228933.pdf', 'H2A_PDFs/H-300-20357-975271.pdf', 'H2A_PDFs/H-300-21006-998351.pdf', 'H2A_PDFs/H-300-22014-831909.pdf', 'H2A_PDFs/H-300-20009-241352.pdf', 'H2A_PDFs/104779_order.pdf', 'H2A_PDFs/99257_order.pdf', 'H2A_PDFs/115969_order.pdf', 'H2A_PDFs/H-300-23086-881434.pdf', 'H2A_PDFs/115829_order.pdf', 'H2A_PDFs/74479_order.pdf', 'H2A_PDFs/117179_order.pdf', 'H2A_PDFs/66774_order.pdf', 'H2A_PDFs/H-300-20260-827359.pdf', 'H2A_PDFs/H-300-20363-980683.pdf', 'H2A_PDFs/H-300-21007-999949.pdf', 'H2A_PDFs/H-300-21026-033893.pdf', 'H2A_PDFs/H-300-21039-063180.pdf', 'H2A_PDFs/H-300-21124-285763.pdf', 'H2A_PDFs/H-300-21253-577257.pdf', 'H2A_PDFs/H-300-21166-398136.pdf', 'H2A_PDFs/H-300-20208-735658.pdf', 'H2A_PDFs/H-300-20150-611826.pdf', 'H2A_PDFs/H-300-20051-337029.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from urllib.parse import urljoin\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"hit.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Column containing URLs\n",
    "column_name = \"Link to H-2A\"\n",
    "urls = df[column_name].dropna().unique()\n",
    "\n",
    "# Create folder for PDFs\n",
    "output_folder = \"H2A_PDFs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Set up Chrome WebDriver (Headless Mode)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  \n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--log-level=3\")  \n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Track successes and failures\n",
    "successful_downloads = []\n",
    "failed_urls = []\n",
    "\n",
    "# Function to check if a URL is a direct PDF\n",
    "def is_pdf(url):\n",
    "    try:\n",
    "        response = requests.head(url, allow_redirects=True, timeout=10)\n",
    "        content_type = response.headers.get(\"Content-Type\", \"\")\n",
    "\n",
    "        if not content_type or \"application/pdf\" not in content_type:\n",
    "            response = requests.get(url, stream=True, timeout=10)\n",
    "            content_type = response.headers.get(\"Content-Type\", \"\")\n",
    "\n",
    "        return \"application/pdf\" in content_type\n",
    "    except requests.exceptions.RequestException:\n",
    "        return False \n",
    "\n",
    "# Function to extract PDF link from a webpage\n",
    "def extract_pdf_from_page(url):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)  \n",
    "\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # Try extracting direct PDF links\n",
    "        for link in soup.find_all(\"a\", href=True):\n",
    "            text = link.text.strip().lower()\n",
    "            if \"view job order\" in text or link[\"href\"].endswith(\".pdf\"):\n",
    "                return urljoin(url, link[\"href\"])\n",
    "\n",
    "        # Look for PDFs in <iframe>\n",
    "        iframe = soup.find(\"iframe\", src=True)\n",
    "        if iframe and iframe[\"src\"].endswith(\".pdf\"):\n",
    "            return urljoin(url, iframe[\"src\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing webpage {url}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Function to download a PDF and track success\n",
    "def download_pdf(pdf_url, source_url):\n",
    "    try:\n",
    "        response = requests.get(pdf_url, stream=True, timeout=10)\n",
    "        content_type = response.headers.get(\"Content-Type\", \"\")\n",
    "\n",
    "        if \"application/pdf\" not in content_type:\n",
    "            print(f\"‚ö†Ô∏è Not a PDF: {pdf_url} (Content-Type: {content_type})\")\n",
    "            failed_urls.append(source_url)\n",
    "            return\n",
    "\n",
    "        filename = os.path.basename(pdf_url)\n",
    "        if not filename.endswith(\".pdf\"):\n",
    "            filename += \".pdf\"  \n",
    "\n",
    "        file_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        # Write PDF file\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                file.write(chunk)\n",
    "\n",
    "        if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
    "            print(f\"‚úÖ Downloaded: {file_path}\")\n",
    "            successful_downloads.append(file_path)\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to save PDF properly: {file_path}\")\n",
    "            failed_urls.append(source_url)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Error downloading PDF from {source_url}: {e}\")\n",
    "        failed_urls.append(source_url)\n",
    "\n",
    "# Function to process each URL\n",
    "def process_url(url):\n",
    "    global driver\n",
    "    try:\n",
    "        if is_pdf(url):  \n",
    "            download_pdf(url, url)\n",
    "        else:\n",
    "            pdf_url = extract_pdf_from_page(url)\n",
    "            if pdf_url:\n",
    "                download_pdf(pdf_url, url)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è No 'View Job Order' PDF found on webpage: {url}\")\n",
    "                failed_urls.append(url)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è WebDriver error, restarting: {e}\")\n",
    "        driver.quit()\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Use multi-threading for faster downloads\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    executor.map(process_url, urls)\n",
    "\n",
    "# Close the Selenium browser\n",
    "driver.quit()\n",
    "\n",
    "# Print final download summary\n",
    "print(\"\\nüìä **Download Summary**\")\n",
    "print(f\"‚úÖ Successfully downloaded PDFs: {len(successful_downloads)}\")\n",
    "print(f\"‚ùå Failed URLs: {len(failed_urls)}\\n\")\n",
    "\n",
    "if successful_downloads:\n",
    "    print(\"‚úÖ **Successfully downloaded PDFs:**\")\n",
    "    for file in successful_downloads:\n",
    "        print(file)\n",
    "\n",
    "if failed_urls:\n",
    "    print(\"\\n‚ö†Ô∏è **Failed to download PDFs from these URLs:**\")\n",
    "    for url in failed_urls:\n",
    "        print(url)\n",
    "\n",
    "# Debugging output\n",
    "print(\"\\nüîç Debugging successful_downloads list:\")\n",
    "print(successful_downloads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
